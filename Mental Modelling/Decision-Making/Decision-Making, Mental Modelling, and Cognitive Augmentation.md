# Human Limitations
Cognitive augmentation begins from an acceptance of limitation. Attention, memory, and reasoning are finite resources (Simon, 1957), but this does not represent a flaw to be corrected; rather, these constraints function as design parameters for how to approach the construction of external supports to extend human cognition. Rather than asking how humans can think more like machines, augmentation asks how we can design ecologies of cognition (Hutchins, 1995) where human minds, tools, and representations (internal and external) can cooperate to overcome [[Descriptive Decision-Making Models#Bounded Rationality|Bounded Rationality]]. 

Human cognition evolved for local, low-dimensional, and socially-embedded contexts (Gigerenzer & Todd, 1999). Modern decision environments, which involve algorithmic systems, data-rich uncertainty, and global interdependence, exceed what our intuitive [[Heuristics]] and [[Schema Theory|Schema]] can process without external assistance. As a result, a mismatch between evolved capacities and technological complexity emerges (Norman, 1993). Cognitive augmentation translates complexity into cognitively-traceable forms, through [[Visualization for Cognitive Augmentation Hub|Visualization]], modelling, structured reasoning prompts, or general feedback systems that make internal thought external. These representations act as mediators between human cognition and the complex, abstract domains we must navigate. 

Traditional decision cycles move from perception -> evaluation -> action. Augmented decision-making introduces the concept of meta-cognitive layers: externalization, reflection, and feedback (Kirsch, 2010). Writing, simulation, and [[Visualization for Cognitive Augmentation Hub|Visualization]] that make internal reasoning external, allow for recursive improvements and enhancements. This recursion is a core element of cognitive augmentation - the capacity to think about thinking, or the practice of "metacognition" (Dunlosky & Metcalfe, 2008). It transforms decision-making from a bounded psychological process to an evolving interaction between human and environment. 
# Normative Models as Augmentation Benchmarks
[[Normative Decision-Making Models|Normative Models]] describe optimal decision outcomes under ideal circumstances. In cognitive augmentation, these models are not instructions for humans - they are reference points against which tool-supported reasoning can be evaluated. As an example, consider Influence Diagrams (Koller & Milch, 2003). Influence Diagrams generalize decision trees and use the principle of maximizing [[Normative Decision-Making Models#Expected Utility Theory|Expected Utility]] through [[Normative Decision-Making Models#Bayesian Decision Theory|Bayesian networks]]. The [[Normative Decision-Making Models|Normative Model]] 
# Descriptive Models for Human-Centered Design

# Heuristics and Augmentation

# AI and Decision Support

## References
- Dunlosky, J., & Metcalfe, J. (2008). _Metacognition_. Sage Publications.
- Gigerenzer, G., & Todd, P. M. (1999). *Simple Heuristics That Make Us Smart.* Oxford University Press.  
- Hutchins, E. (1995). *Cognition in the Wild.* MIT Press.
- Kirsh, D. (2010). *Thinking with external representations.* *AI & Society, 25*(4), 441–454.
- Koller, D., &  Milch, B. (2003). _Multi‑agent influence diagrams for representing and solving games._ _Games and Economic Behavior, 45_(1), 181–221. https://doi.org/10.1016/S0899‑8256(02)00544‑4
- Norman, D. A. (1993). *Things That Make Us Smart: Defending Human Attributes in the Age of the Machine.* Addison-Wesley.
- Simon, H. A. (1957). *Models of Man: Social and Rational.* Wiley.