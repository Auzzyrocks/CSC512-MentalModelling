
*"All models are wrong, but some are useful"* -  George E. P. Box, Statistician

# Limitations 
While George Box was referring to statistical models, this aphorism holds true for mental models. Most research into mental models acknowledges as much, typified by Forrester who wrote that "*The mental image of the world around us that we carry in our heads is a model. One does not have a city or a government, or a country in his head. He has only selected concepts and relationships, which he uses to represent the real system."* 

If one cannot fully carry a city, or a government, or a the complete set of physical laws and interactions that describe something as simple as a ball bouncing in ones head, one cannot possibly evaluate the complete set of possible outcomes within a mental model, only an approximation of such. Forrester again states as much, writing that *"the number of variables (people) can in fact properly relate to one another is very limited. The intuitive judgment of even a skilled investigator is quite unreliable in anticipating the dynamic behavior of a simple information-feedback system of perhaps five or six variables."* 

[https://web.wpi.edu/Images/CMS/SSPS/06.pdf]

## [[Mental Modelling HEADER#Holtrop et al.|Holtrop et al.]]
Other related views abound. Holtrop et al. express a similar sentiment to Forrester, highlighting that many mental models, specifically inaccurate ones, are shared across society. They go on to identify a commonly held, but inaccurate, physics model that his been disproved since Gallileo, but is still commonly found today.

*Mental models are always inaccurate to some extent, insofar as they are heuristics and involve stereotypes and expectations to make sense of the world. They cannot encapsulate all aspects of the world and tend to make imperfect predictions. When commonly shared mental models make inaccurate predictions, it can be a source of scientific insight and psychological fascination. For example, a common incorrect mental model about the physical world is that heavier objects fall faster than lighter ones. This mental model results in the expectation that a 20-pound ball will fall faster than a one-ounce ball, an expectation that was disproved compellingly by Galileo, but that is so counterintuitive that we must continue to dispel it in schoolchildren today.*

(https://pmc.ncbi.nlm.nih.gov/articles/PMC8290163/#s2)

# Biases

Many biases in mental modeling, and decision making more broadly, exist. These are a tendency for human reasoning to fail to meet logical or probablistic standards, and are caused by a variety of reasons. Below are only a selection of existing well-known biases.
## Belief Bias
Several specific types of bias have been commonly observed in mental models and the broader category of decision making. As explained below by Torrens et al. there exists a belief bias, such that people are more willing to accept a mental model that produces an outcome that aligns with their belief system as opposed to their beliefs. Torres et al. not that this bias also applies to  believable outcomes, which are more readily accepted, as opposed to a model that produces a less-believable outcome which may actually be the correct outcome. 

*According to mental models theory, the effect of beliefs is to pre-empt the  
search for alternative models. If the first model of the premises yields a  
believable conclusion, then the search for further models may be terminated.  
However, if the first conclusion is unbelievable, then the search for alternatives  
may be continued and a different conclusion reached. In this manner, people  
accept more believable than unbelievable conclusions, even when those  
conclusions are not necessarily valid.*

[https://www.tandfonline.com/doi/epdf/10.1080/135467899394066?needAccess=true]

## Conjunction Fallacy 
Similar to many other biases, conjunction fallacy results from an inability to correctly evaluate the probability of an event. The conjunction fallacy specifically refers to the conjunction of two events and the probabilistic limitations. Specifically, given events A and B, the probability of event AB can never be greater than the probability of event A alone. However, mental models often fail to accept this, as explained below by Gigerenzer in an elegant example known as the Linda Problem: 

*Imagine you are a subject in a psychological experiment. In front of you is a text problem, and you begin to read:

*Linda is 31 years old, single, outspoken and very bright. She majored in philosophy. As a student, she was deeply concerned with issues of discrimination and social justice, and also participated in antinuclear demonstrations. Which of two alternatives is more probable?  
	(a) Linda is a bank teller.  
	(b) Linda is a bank teller and is active in the feminist movement.*

*Which alternative would you choose? Assume you chose (b), just as most subjects in previous experiments did. The experimenter explains to you that (b) is the conjunction of two events, namely that Linda is a bank teller **and** is active in the feminist movement, whereas (a) is one of the constituents of the conjunction. Because the probability of a conjunction of two events cannot be greater than that of one of its constituents, the correct answer is (a), not (b), the experimenter says. Therefore, your judgment is recorded as an instance of a reasoning error, known as the **conjunction fallacy.***

[https://pure.mpg.de/rest/items/item_2547860/component/file_2566394/content]
*This may actually be a decision-making bias and not a mental model bias*

## Other Biases 
### Base-rate Fallacy
### Overconfidence Bias 


# Bias, Limitations and Cognitive Augmentation 
Various tools and technologies exist to help augment the mental modeling process. Since mental models are continually evolving and/or being replaced, there is constant opportunity to improve our internal modeling process, which can lead to better decision making and understanding of our environment. 

## Fuzzy Cognitive Mapping

https://link.springer.com/chapter/10.1007/978-3-031-01919-7_6
